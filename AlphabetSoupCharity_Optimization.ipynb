{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27ac9c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"charity_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49984c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df = application_df.drop(columns=['EIN','NAME'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff6ca14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            17\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "application_df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1645fc64",
   "metadata": {},
   "source": [
    "Noisy variables are removed from features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f804ad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLICATION_TYPE Data Processing\n",
    "application_df = application_df.drop(columns=['APPLICATION_TYPE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5966e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "Other     2261\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CLASSIFICATION Data Processing\n",
    "\n",
    "# Look at CLASSIFICATION value counts for binning\n",
    "class_counts = application_df.CLASSIFICATION.value_counts()\n",
    "\n",
    "# Determine which values to replace if counts are less than ..?\n",
    "replace_class = list(class_counts[class_counts < 1883].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in replace_class:\n",
    "    application_df.CLASSIFICATION = application_df.CLASSIFICATION.replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df.CLASSIFICATION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a1d0923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Processing\n",
    "\n",
    "# Generate our categorical variable lists\n",
    "application_cat = [\"AFFILIATION\",\"CLASSIFICATION\",\"USE_CASE\",\"ORGANIZATION\",\"INCOME_AMT\",\"SPECIAL_CONSIDERATIONS\"]\n",
    "\n",
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(application_df[application_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(application_cat)\n",
    "\n",
    "# Merge one-hot encoded features and drop the originals\n",
    "application_df = application_df.merge(encode_df, left_index=True, right_index=True).drop(columns=application_cat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45bff209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATUS                             2\n",
       "ASK_AMT                         8747\n",
       "IS_SUCCESSFUL                      2\n",
       "APPLICATION_TYPE_Other             2\n",
       "APPLICATION_TYPE_T10               2\n",
       "APPLICATION_TYPE_T19               2\n",
       "APPLICATION_TYPE_T3                2\n",
       "APPLICATION_TYPE_T4                2\n",
       "APPLICATION_TYPE_T5                2\n",
       "APPLICATION_TYPE_T6                2\n",
       "APPLICATION_TYPE_T7                2\n",
       "APPLICATION_TYPE_T8                2\n",
       "AFFILIATION_CompanySponsored       2\n",
       "AFFILIATION_Family/Parent          2\n",
       "AFFILIATION_Independent            2\n",
       "AFFILIATION_National               2\n",
       "AFFILIATION_Other                  2\n",
       "AFFILIATION_Regional               2\n",
       "CLASSIFICATION_C1000               2\n",
       "CLASSIFICATION_C1200               2\n",
       "CLASSIFICATION_C2000               2\n",
       "CLASSIFICATION_C2100               2\n",
       "CLASSIFICATION_C3000               2\n",
       "CLASSIFICATION_Other               2\n",
       "USE_CASE_CommunityServ             2\n",
       "USE_CASE_Heathcare                 2\n",
       "USE_CASE_Other                     2\n",
       "USE_CASE_Preservation              2\n",
       "USE_CASE_ProductDev                2\n",
       "ORGANIZATION_Association           2\n",
       "ORGANIZATION_Co-operative          2\n",
       "ORGANIZATION_Corporation           2\n",
       "ORGANIZATION_Trust                 2\n",
       "INCOME_AMT_0                       2\n",
       "INCOME_AMT_1-9999                  2\n",
       "INCOME_AMT_10000-24999             2\n",
       "INCOME_AMT_100000-499999           2\n",
       "INCOME_AMT_10M-50M                 2\n",
       "INCOME_AMT_1M-5M                   2\n",
       "INCOME_AMT_25000-99999             2\n",
       "INCOME_AMT_50M+                    2\n",
       "INCOME_AMT_5M-10M                  2\n",
       "SPECIAL_CONSIDERATIONS_N           2\n",
       "SPECIAL_CONSIDERATIONS_Y           2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f4757de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = application_df.IS_SUCCESSFUL\n",
    "X = application_df.drop(\"IS_SUCCESSFUL\",axis=1)\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=0,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "793f9d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1b61ff",
   "metadata": {},
   "source": [
    "Additional hidden layers + Additional neurons per hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a58624fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 21:50:26.387823: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-02 21:50:26.390983: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 80)                2800      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 9,361\n",
      "Trainable params: 9,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "nodes_hidden_layer1 = 80\n",
    "nodes_hidden_layer2 = 40\n",
    "nodes_hidden_layer3 = 40\n",
    "nodes_hidden_layer4 = 40\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=nodes_hidden_layer1, activation=\"relu\", input_dim=number_input_features))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=nodes_hidden_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=nodes_hidden_layer3, activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=nodes_hidden_layer4, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fd3d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c538730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 25724 samples\n",
      "Epoch 1/100\n",
      "25724/25724 [==============================] - 5s 205us/sample - loss: 0.5930 - accuracy: 0.6976\n",
      "Epoch 2/100\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 0.5812 - accuracy: 0.7049\n",
      "Epoch 3/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.5784 - accuracy: 0.7074\n",
      "Epoch 4/100\n",
      "25724/25724 [==============================] - 3s 109us/sample - loss: 0.5774 - accuracy: 0.7077\n",
      "Epoch 5/100\n",
      "25504/25724 [============================>.] - ETA: 0s - loss: 0.5772 - accuracy: 0.7091\n",
      "Epoch 00005: saving model to checkpoints2/weights.05hdf5\n",
      "25724/25724 [==============================] - 3s 120us/sample - loss: 0.5771 - accuracy: 0.7089\n",
      "Epoch 6/100\n",
      "25724/25724 [==============================] - 4s 136us/sample - loss: 0.5758 - accuracy: 0.7093\n",
      "Epoch 7/100\n",
      "25724/25724 [==============================] - 4s 164us/sample - loss: 0.5752 - accuracy: 0.7089\n",
      "Epoch 8/100\n",
      "25724/25724 [==============================] - 6s 219us/sample - loss: 0.5751 - accuracy: 0.7101\n",
      "Epoch 9/100\n",
      "25724/25724 [==============================] - 5s 186us/sample - loss: 0.5751 - accuracy: 0.7100\n",
      "Epoch 10/100\n",
      "25632/25724 [============================>.] - ETA: 0s - loss: 0.5747 - accuracy: 0.7106\n",
      "Epoch 00010: saving model to checkpoints2/weights.10hdf5\n",
      "25724/25724 [==============================] - 4s 159us/sample - loss: 0.5746 - accuracy: 0.7107\n",
      "Epoch 11/100\n",
      "25724/25724 [==============================] - 5s 188us/sample - loss: 0.5742 - accuracy: 0.7109\n",
      "Epoch 12/100\n",
      "25724/25724 [==============================] - 5s 197us/sample - loss: 0.5737 - accuracy: 0.7113\n",
      "Epoch 13/100\n",
      "25724/25724 [==============================] - 7s 256us/sample - loss: 0.5741 - accuracy: 0.7133\n",
      "Epoch 14/100\n",
      "25724/25724 [==============================] - 4s 147us/sample - loss: 0.5732 - accuracy: 0.7128\n",
      "Epoch 15/100\n",
      "25568/25724 [============================>.] - ETA: 0s - loss: 0.5739 - accuracy: 0.7122\n",
      "Epoch 00015: saving model to checkpoints2/weights.15hdf5\n",
      "25724/25724 [==============================] - 4s 139us/sample - loss: 0.5732 - accuracy: 0.7127\n",
      "Epoch 16/100\n",
      "25724/25724 [==============================] - 4s 139us/sample - loss: 0.5724 - accuracy: 0.7123\n",
      "Epoch 17/100\n",
      "25724/25724 [==============================] - 3s 123us/sample - loss: 0.5723 - accuracy: 0.7130\n",
      "Epoch 18/100\n",
      "25724/25724 [==============================] - 3s 120us/sample - loss: 0.5724 - accuracy: 0.7122\n",
      "Epoch 19/100\n",
      "25724/25724 [==============================] - 3s 121us/sample - loss: 0.5718 - accuracy: 0.7129\n",
      "Epoch 20/100\n",
      "25664/25724 [============================>.] - ETA: 0s - loss: 0.5710 - accuracy: 0.7130\n",
      "Epoch 00020: saving model to checkpoints2/weights.20hdf5\n",
      "25724/25724 [==============================] - 4s 151us/sample - loss: 0.5712 - accuracy: 0.7128\n",
      "Epoch 21/100\n",
      "25724/25724 [==============================] - 4s 137us/sample - loss: 0.5720 - accuracy: 0.7123\n",
      "Epoch 22/100\n",
      "25724/25724 [==============================] - 3s 131us/sample - loss: 0.5710 - accuracy: 0.7126\n",
      "Epoch 23/100\n",
      "25724/25724 [==============================] - 3s 122us/sample - loss: 0.5709 - accuracy: 0.7128\n",
      "Epoch 24/100\n",
      "25724/25724 [==============================] - 3s 126us/sample - loss: 0.5710 - accuracy: 0.7131\n",
      "Epoch 25/100\n",
      "25344/25724 [============================>.] - ETA: 0s - loss: 0.5706 - accuracy: 0.7135\n",
      "Epoch 00025: saving model to checkpoints2/weights.25hdf5\n",
      "25724/25724 [==============================] - 3s 123us/sample - loss: 0.5707 - accuracy: 0.7135\n",
      "Epoch 26/100\n",
      "25724/25724 [==============================] - 3s 134us/sample - loss: 0.5703 - accuracy: 0.7133\n",
      "Epoch 27/100\n",
      "25724/25724 [==============================] - 3s 122us/sample - loss: 0.5708 - accuracy: 0.7131\n",
      "Epoch 28/100\n",
      "25724/25724 [==============================] - 3s 121us/sample - loss: 0.5700 - accuracy: 0.7137\n",
      "Epoch 29/100\n",
      "25724/25724 [==============================] - 3s 125us/sample - loss: 0.5703 - accuracy: 0.7145\n",
      "Epoch 30/100\n",
      "25408/25724 [============================>.] - ETA: 0s - loss: 0.5706 - accuracy: 0.7135\n",
      "Epoch 00030: saving model to checkpoints2/weights.30hdf5\n",
      "25724/25724 [==============================] - 3s 130us/sample - loss: 0.5704 - accuracy: 0.7137\n",
      "Epoch 31/100\n",
      "25724/25724 [==============================] - 3s 136us/sample - loss: 0.5698 - accuracy: 0.7139\n",
      "Epoch 32/100\n",
      "25724/25724 [==============================] - 3s 135us/sample - loss: 0.5700 - accuracy: 0.7133\n",
      "Epoch 33/100\n",
      "25724/25724 [==============================] - 4s 165us/sample - loss: 0.5697 - accuracy: 0.7144\n",
      "Epoch 34/100\n",
      "25724/25724 [==============================] - 4s 151us/sample - loss: 0.5691 - accuracy: 0.7142\n",
      "Epoch 35/100\n",
      "25696/25724 [============================>.] - ETA: 0s - loss: 0.5694 - accuracy: 0.7142\n",
      "Epoch 00035: saving model to checkpoints2/weights.35hdf5\n",
      "25724/25724 [==============================] - 3s 121us/sample - loss: 0.5695 - accuracy: 0.7141\n",
      "Epoch 36/100\n",
      "25724/25724 [==============================] - 3s 130us/sample - loss: 0.5695 - accuracy: 0.7138\n",
      "Epoch 37/100\n",
      "25724/25724 [==============================] - 3s 118us/sample - loss: 0.5688 - accuracy: 0.7148\n",
      "Epoch 38/100\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 0.5690 - accuracy: 0.7136\n",
      "Epoch 39/100\n",
      "25724/25724 [==============================] - 3s 112us/sample - loss: 0.5692 - accuracy: 0.7144\n",
      "Epoch 40/100\n",
      "25312/25724 [============================>.] - ETA: 0s - loss: 0.5681 - accuracy: 0.7152\n",
      "Epoch 00040: saving model to checkpoints2/weights.40hdf5\n",
      "25724/25724 [==============================] - 3s 132us/sample - loss: 0.5685 - accuracy: 0.7149\n",
      "Epoch 41/100\n",
      "25724/25724 [==============================] - 3s 128us/sample - loss: 0.5690 - accuracy: 0.7131\n",
      "Epoch 42/100\n",
      "25724/25724 [==============================] - 3s 127us/sample - loss: 0.5686 - accuracy: 0.7147\n",
      "Epoch 43/100\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 0.5688 - accuracy: 0.7145\n",
      "Epoch 44/100\n",
      "25724/25724 [==============================] - 3s 114us/sample - loss: 0.5680 - accuracy: 0.7149\n",
      "Epoch 45/100\n",
      "25696/25724 [============================>.] - ETA: 0s - loss: 0.5685 - accuracy: 0.7155\n",
      "Epoch 00045: saving model to checkpoints2/weights.45hdf5\n",
      "25724/25724 [==============================] - 3s 112us/sample - loss: 0.5684 - accuracy: 0.7156\n",
      "Epoch 46/100\n",
      "25724/25724 [==============================] - 3s 116us/sample - loss: 0.5687 - accuracy: 0.7145\n",
      "Epoch 47/100\n",
      "25724/25724 [==============================] - 6s 216us/sample - loss: 0.5684 - accuracy: 0.7145\n",
      "Epoch 48/100\n",
      "25724/25724 [==============================] - 9s 340us/sample - loss: 0.5681 - accuracy: 0.7150\n",
      "Epoch 49/100\n",
      "25724/25724 [==============================] - 3s 110us/sample - loss: 0.5683 - accuracy: 0.7150\n",
      "Epoch 50/100\n",
      "25408/25724 [============================>.] - ETA: 0s - loss: 0.5680 - accuracy: 0.7152\n",
      "Epoch 00050: saving model to checkpoints2/weights.50hdf5\n",
      "25724/25724 [==============================] - 3s 111us/sample - loss: 0.5679 - accuracy: 0.7154\n",
      "Epoch 51/100\n",
      "25724/25724 [==============================] - 5s 197us/sample - loss: 0.5681 - accuracy: 0.7149\n",
      "Epoch 52/100\n",
      "25724/25724 [==============================] - 4s 172us/sample - loss: 0.5675 - accuracy: 0.7152\n",
      "Epoch 53/100\n",
      "25724/25724 [==============================] - 12s 460us/sample - loss: 0.5678 - accuracy: 0.7155\n",
      "Epoch 54/100\n",
      "25724/25724 [==============================] - 4s 143us/sample - loss: 0.5682 - accuracy: 0.7145\n",
      "Epoch 55/100\n",
      "25536/25724 [============================>.] - ETA: 0s - loss: 0.5678 - accuracy: 0.7150\n",
      "Epoch 00055: saving model to checkpoints2/weights.55hdf5\n",
      "25724/25724 [==============================] - 3s 131us/sample - loss: 0.5679 - accuracy: 0.7150\n",
      "Epoch 56/100\n",
      "25724/25724 [==============================] - 10s 394us/sample - loss: 0.5678 - accuracy: 0.7156\n",
      "Epoch 57/100\n",
      "25724/25724 [==============================] - 14s 540us/sample - loss: 0.5673 - accuracy: 0.7159\n",
      "Epoch 58/100\n",
      "25724/25724 [==============================] - 14s 560us/sample - loss: 0.5677 - accuracy: 0.7155\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25724/25724 [==============================] - 22s 858us/sample - loss: 0.5674 - accuracy: 0.7150\n",
      "Epoch 60/100\n",
      "25664/25724 [============================>.] - ETA: 0s - loss: 0.5675 - accuracy: 0.7157\n",
      "Epoch 00060: saving model to checkpoints2/weights.60hdf5\n",
      "25724/25724 [==============================] - 19s 743us/sample - loss: 0.5674 - accuracy: 0.7158\n",
      "Epoch 61/100\n",
      "25724/25724 [==============================] - 10s 402us/sample - loss: 0.5673 - accuracy: 0.7158\n",
      "Epoch 62/100\n",
      "25724/25724 [==============================] - 17s 651us/sample - loss: 0.5672 - accuracy: 0.7152\n",
      "Epoch 63/100\n",
      "25724/25724 [==============================] - 18s 690us/sample - loss: 0.5674 - accuracy: 0.7162\n",
      "Epoch 64/100\n",
      "25724/25724 [==============================] - 18s 706us/sample - loss: 0.5673 - accuracy: 0.7156\n",
      "Epoch 65/100\n",
      "25280/25724 [============================>.] - ETA: 0s - loss: 0.5674 - accuracy: 0.7152\n",
      "Epoch 00065: saving model to checkpoints2/weights.65hdf5\n",
      "25724/25724 [==============================] - 19s 735us/sample - loss: 0.5673 - accuracy: 0.7153\n",
      "Epoch 66/100\n",
      "25724/25724 [==============================] - 10s 407us/sample - loss: 0.5673 - accuracy: 0.7151\n",
      "Epoch 67/100\n",
      "25724/25724 [==============================] - 21s 823us/sample - loss: 0.5672 - accuracy: 0.7154\n",
      "Epoch 68/100\n",
      "25724/25724 [==============================] - 16s 612us/sample - loss: 0.5670 - accuracy: 0.7158\n",
      "Epoch 69/100\n",
      "25724/25724 [==============================] - 16s 620us/sample - loss: 0.5666 - accuracy: 0.7159\n",
      "Epoch 70/100\n",
      "25472/25724 [============================>.] - ETA: 0s - loss: 0.5672 - accuracy: 0.7152\n",
      "Epoch 00070: saving model to checkpoints2/weights.70hdf5\n",
      "25724/25724 [==============================] - 16s 631us/sample - loss: 0.5666 - accuracy: 0.7158\n",
      "Epoch 71/100\n",
      "25724/25724 [==============================] - 11s 420us/sample - loss: 0.5666 - accuracy: 0.7153\n",
      "Epoch 72/100\n",
      "25724/25724 [==============================] - 24s 932us/sample - loss: 0.5664 - accuracy: 0.7160\n",
      "Epoch 73/100\n",
      "25724/25724 [==============================] - 4s 138us/sample - loss: 0.5677 - accuracy: 0.7159\n",
      "Epoch 74/100\n",
      "25724/25724 [==============================] - 5s 195us/sample - loss: 0.5669 - accuracy: 0.7158\n",
      "Epoch 75/100\n",
      "25376/25724 [============================>.] - ETA: 0s - loss: 0.5665 - accuracy: 0.7155\n",
      "Epoch 00075: saving model to checkpoints2/weights.75hdf5\n",
      "25724/25724 [==============================] - 4s 153us/sample - loss: 0.5668 - accuracy: 0.7153\n",
      "Epoch 76/100\n",
      "25724/25724 [==============================] - 4s 160us/sample - loss: 0.5666 - accuracy: 0.7160\n",
      "Epoch 77/100\n",
      "25724/25724 [==============================] - 6s 223us/sample - loss: 0.5670 - accuracy: 0.7155\n",
      "Epoch 78/100\n",
      "25724/25724 [==============================] - 17s 676us/sample - loss: 0.5665 - accuracy: 0.7157\n",
      "Epoch 79/100\n",
      "25724/25724 [==============================] - 12s 473us/sample - loss: 0.5664 - accuracy: 0.7163\n",
      "Epoch 80/100\n",
      "25600/25724 [============================>.] - ETA: 0s - loss: 0.5661 - accuracy: 0.7163\n",
      "Epoch 00080: saving model to checkpoints2/weights.80hdf5\n",
      "25724/25724 [==============================] - 9s 362us/sample - loss: 0.5661 - accuracy: 0.7163\n",
      "Epoch 81/100\n",
      "25724/25724 [==============================] - 5s 175us/sample - loss: 0.5669 - accuracy: 0.7154\n",
      "Epoch 82/100\n",
      "25724/25724 [==============================] - 3s 118us/sample - loss: 0.5662 - accuracy: 0.7161\n",
      "Epoch 83/100\n",
      "25724/25724 [==============================] - 3s 119us/sample - loss: 0.5664 - accuracy: 0.7161\n",
      "Epoch 84/100\n",
      "25724/25724 [==============================] - 3s 111us/sample - loss: 0.5661 - accuracy: 0.7156\n",
      "Epoch 85/100\n",
      "25504/25724 [============================>.] - ETA: 0s - loss: 0.5661 - accuracy: 0.7148\n",
      "Epoch 00085: saving model to checkpoints2/weights.85hdf5\n",
      "25724/25724 [==============================] - 3s 121us/sample - loss: 0.5663 - accuracy: 0.7145\n",
      "Epoch 86/100\n",
      "25724/25724 [==============================] - 4s 157us/sample - loss: 0.5668 - accuracy: 0.7150\n",
      "Epoch 87/100\n",
      "25724/25724 [==============================] - 5s 177us/sample - loss: 0.5660 - accuracy: 0.7159\n",
      "Epoch 88/100\n",
      "25724/25724 [==============================] - 3s 118us/sample - loss: 0.5665 - accuracy: 0.7146\n",
      "Epoch 89/100\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 0.5666 - accuracy: 0.7135\n",
      "Epoch 90/100\n",
      "25536/25724 [============================>.] - ETA: 0s - loss: 0.5662 - accuracy: 0.7145\n",
      "Epoch 00090: saving model to checkpoints2/weights.90hdf5\n",
      "25724/25724 [==============================] - 3s 114us/sample - loss: 0.5661 - accuracy: 0.7145\n",
      "Epoch 91/100\n",
      "25724/25724 [==============================] - 3s 132us/sample - loss: 0.5663 - accuracy: 0.7152\n",
      "Epoch 92/100\n",
      "25724/25724 [==============================] - 3s 124us/sample - loss: 0.5669 - accuracy: 0.7161\n",
      "Epoch 93/100\n",
      "25724/25724 [==============================] - 3s 123us/sample - loss: 0.5662 - accuracy: 0.7159\n",
      "Epoch 94/100\n",
      "25724/25724 [==============================] - 3s 120us/sample - loss: 0.5655 - accuracy: 0.7153\n",
      "Epoch 95/100\n",
      "25344/25724 [============================>.] - ETA: 0s - loss: 0.5666 - accuracy: 0.7145\n",
      "Epoch 00095: saving model to checkpoints2/weights.95hdf5\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 0.5660 - accuracy: 0.7149\n",
      "Epoch 96/100\n",
      "25724/25724 [==============================] - 3s 115us/sample - loss: 0.5665 - accuracy: 0.7150\n",
      "Epoch 97/100\n",
      "25724/25724 [==============================] - 8s 321us/sample - loss: 0.5662 - accuracy: 0.7156\n",
      "Epoch 98/100\n",
      "25724/25724 [==============================] - 16s 633us/sample - loss: 0.5659 - accuracy: 0.7153\n",
      "Epoch 99/100\n",
      "25724/25724 [==============================] - 23s 896us/sample - loss: 0.5653 - accuracy: 0.7159\n",
      "Epoch 100/100\n",
      "25664/25724 [============================>.] - ETA: 0s - loss: 0.5670 - accuracy: 0.7158\n",
      "Epoch 00100: saving model to checkpoints2/weights.100hdf5\n",
      "25724/25724 [==============================] - 21s 798us/sample - loss: 0.5669 - accuracy: 0.7159\n"
     ]
    }
   ],
   "source": [
    "# Import checkpoint dependencies\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the checkpoint path and filenames\n",
    "os.makedirs(\"checkpoints2/\", exist_ok=True)\n",
    "checkpoint_path = \"checkpoints2/weights.{epoch:02d}hdf5\"\n",
    "\n",
    "# Create a callback that saves the model's weights every epoch\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch',\n",
    "    period=5)\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(np.asarray(X_train_scaled),np.asarray(y_train),epochs=100,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a428b436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/1 - 1s - loss: 0.5606 - accuracy: 0.7100\n",
      "Loss: 0.5834909761890378, Accuracy: 0.7099708318710327\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(np.asarray(X_test_scaled),np.asarray(y_test),verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc21e80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 80)                2800      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 9,361\n",
      "Trainable params: 9,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "nodes_hidden_layer1 = 80\n",
    "nodes_hidden_layer2 = 40\n",
    "nodes_hidden_layer3 = 40\n",
    "nodes_hidden_layer4 = 40\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=nodes_hidden_layer1, activation=\"relu\", input_dim=number_input_features))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=nodes_hidden_layer2, activation=\"tanh\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=nodes_hidden_layer3, activation=\"tanh\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=nodes_hidden_layer4, activation=\"tanh\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "498fa486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b485e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 25724 samples\n",
      "Epoch 1/100\n",
      "25724/25724 [==============================] - 5s 202us/sample - loss: 0.5928 - accuracy: 0.6945\n",
      "Epoch 2/100\n",
      "25724/25724 [==============================] - 4s 137us/sample - loss: 0.5817 - accuracy: 0.7063\n",
      "Epoch 3/100\n",
      "25724/25724 [==============================] - 3s 128us/sample - loss: 0.5798 - accuracy: 0.7072\n",
      "Epoch 4/100\n",
      "25724/25724 [==============================] - 3s 134us/sample - loss: 0.5787 - accuracy: 0.7064\n",
      "Epoch 5/100\n",
      "25536/25724 [============================>.] - ETA: 0s - loss: 0.5784 - accuracy: 0.7083\n",
      "Epoch 00005: saving model to checkpoints2/weights.05hdf5\n",
      "25724/25724 [==============================] - 4s 138us/sample - loss: 0.5784 - accuracy: 0.7082\n",
      "Epoch 6/100\n",
      "25724/25724 [==============================] - 4s 144us/sample - loss: 0.5777 - accuracy: 0.7088\n",
      "Epoch 7/100\n",
      "25724/25724 [==============================] - 4s 140us/sample - loss: 0.5769 - accuracy: 0.7091\n",
      "Epoch 8/100\n",
      "25724/25724 [==============================] - 3s 122us/sample - loss: 0.5766 - accuracy: 0.7075\n",
      "Epoch 9/100\n",
      "25724/25724 [==============================] - 3s 128us/sample - loss: 0.5758 - accuracy: 0.7113\n",
      "Epoch 10/100\n",
      "25664/25724 [============================>.] - ETA: 0s - loss: 0.5752 - accuracy: 0.7102\n",
      "Epoch 00010: saving model to checkpoints2/weights.10hdf5\n",
      "25724/25724 [==============================] - 3s 127us/sample - loss: 0.5751 - accuracy: 0.7102\n",
      "Epoch 11/100\n",
      "25724/25724 [==============================] - 4s 155us/sample - loss: 0.5747 - accuracy: 0.7116\n",
      "Epoch 12/100\n",
      "25724/25724 [==============================] - 6s 219us/sample - loss: 0.5750 - accuracy: 0.7091\n",
      "Epoch 13/100\n",
      "25724/25724 [==============================] - 12s 455us/sample - loss: 0.5739 - accuracy: 0.7112\n",
      "Epoch 14/100\n",
      "25724/25724 [==============================] - 3s 119us/sample - loss: 0.5736 - accuracy: 0.7110\n",
      "Epoch 15/100\n",
      "25600/25724 [============================>.] - ETA: 0s - loss: 0.5735 - accuracy: 0.7111\n",
      "Epoch 00015: saving model to checkpoints2/weights.15hdf5\n",
      "25724/25724 [==============================] - 3s 116us/sample - loss: 0.5737 - accuracy: 0.7107\n",
      "Epoch 16/100\n",
      "25724/25724 [==============================] - 3s 130us/sample - loss: 0.5728 - accuracy: 0.7127\n",
      "Epoch 17/100\n",
      "25724/25724 [==============================] - 4s 146us/sample - loss: 0.5723 - accuracy: 0.7112\n",
      "Epoch 18/100\n",
      "25724/25724 [==============================] - 3s 128us/sample - loss: 0.5724 - accuracy: 0.7106\n",
      "Epoch 19/100\n",
      "25724/25724 [==============================] - 4s 154us/sample - loss: 0.5723 - accuracy: 0.7112\n",
      "Epoch 20/100\n",
      "25536/25724 [============================>.] - ETA: 0s - loss: 0.5719 - accuracy: 0.7135\n",
      "Epoch 00020: saving model to checkpoints2/weights.20hdf5\n",
      "25724/25724 [==============================] - 4s 153us/sample - loss: 0.5718 - accuracy: 0.7134\n",
      "Epoch 21/100\n",
      "25724/25724 [==============================] - 9s 336us/sample - loss: 0.5715 - accuracy: 0.7118\n",
      "Epoch 22/100\n",
      "25724/25724 [==============================] - 10s 408us/sample - loss: 0.5717 - accuracy: 0.7107\n",
      "Epoch 23/100\n",
      "25724/25724 [==============================] - 6s 218us/sample - loss: 0.5712 - accuracy: 0.7114\n",
      "Epoch 24/100\n",
      "25724/25724 [==============================] - 4s 157us/sample - loss: 0.5710 - accuracy: 0.7138\n",
      "Epoch 25/100\n",
      "25632/25724 [============================>.] - ETA: 0s - loss: 0.5712 - accuracy: 0.7120\n",
      "Epoch 00025: saving model to checkpoints2/weights.25hdf5\n",
      "25724/25724 [==============================] - 3s 123us/sample - loss: 0.5710 - accuracy: 0.7122\n",
      "Epoch 26/100\n",
      "25724/25724 [==============================] - 8s 301us/sample - loss: 0.5705 - accuracy: 0.7127\n",
      "Epoch 27/100\n",
      "25724/25724 [==============================] - 11s 445us/sample - loss: 0.5705 - accuracy: 0.7126\n",
      "Epoch 28/100\n",
      "25724/25724 [==============================] - 12s 478us/sample - loss: 0.5704 - accuracy: 0.7105\n",
      "Epoch 29/100\n",
      "25724/25724 [==============================] - 6s 233us/sample - loss: 0.5699 - accuracy: 0.7136\n",
      "Epoch 30/100\n",
      "25632/25724 [============================>.] - ETA: 0s - loss: 0.5698 - accuracy: 0.7148\n",
      "Epoch 00030: saving model to checkpoints2/weights.30hdf5\n",
      "25724/25724 [==============================] - 10s 384us/sample - loss: 0.5699 - accuracy: 0.7147\n",
      "Epoch 31/100\n",
      "25724/25724 [==============================] - 11s 410us/sample - loss: 0.5698 - accuracy: 0.7133\n",
      "Epoch 32/100\n",
      "25724/25724 [==============================] - 12s 466us/sample - loss: 0.5695 - accuracy: 0.7139\n",
      "Epoch 33/100\n",
      "25724/25724 [==============================] - 14s 547us/sample - loss: 0.5697 - accuracy: 0.7125\n",
      "Epoch 34/100\n",
      "25724/25724 [==============================] - 12s 485us/sample - loss: 0.5696 - accuracy: 0.7138\n",
      "Epoch 35/100\n",
      "25632/25724 [============================>.] - ETA: 0s - loss: 0.5689 - accuracy: 0.7141\n",
      "Epoch 00035: saving model to checkpoints2/weights.35hdf5\n",
      "25724/25724 [==============================] - 7s 289us/sample - loss: 0.5692 - accuracy: 0.7137\n",
      "Epoch 36/100\n",
      "25724/25724 [==============================] - 12s 455us/sample - loss: 0.5690 - accuracy: 0.7139\n",
      "Epoch 37/100\n",
      "25724/25724 [==============================] - 10s 397us/sample - loss: 0.5689 - accuracy: 0.7122\n",
      "Epoch 38/100\n",
      "25724/25724 [==============================] - 13s 512us/sample - loss: 0.5687 - accuracy: 0.7131\n",
      "Epoch 39/100\n",
      "25724/25724 [==============================] - 11s 422us/sample - loss: 0.5687 - accuracy: 0.7144\n",
      "Epoch 40/100\n",
      "25696/25724 [============================>.] - ETA: 0s - loss: 0.5686 - accuracy: 0.7149\n",
      "Epoch 00040: saving model to checkpoints2/weights.40hdf5\n",
      "25724/25724 [==============================] - 13s 497us/sample - loss: 0.5685 - accuracy: 0.7148\n",
      "Epoch 41/100\n",
      "25724/25724 [==============================] - 14s 539us/sample - loss: 0.5684 - accuracy: 0.7146\n",
      "Epoch 42/100\n",
      "25724/25724 [==============================] - 11s 409us/sample - loss: 0.5685 - accuracy: 0.7130\n",
      "Epoch 43/100\n",
      "25724/25724 [==============================] - 11s 423us/sample - loss: 0.5691 - accuracy: 0.7159\n",
      "Epoch 44/100\n",
      "25724/25724 [==============================] - 10s 401us/sample - loss: 0.5686 - accuracy: 0.7141\n",
      "Epoch 45/100\n",
      "25696/25724 [============================>.] - ETA: 0s - loss: 0.5685 - accuracy: 0.7149\n",
      "Epoch 00045: saving model to checkpoints2/weights.45hdf5\n",
      "25724/25724 [==============================] - 9s 361us/sample - loss: 0.5684 - accuracy: 0.7149\n",
      "Epoch 46/100\n",
      "25724/25724 [==============================] - 8s 312us/sample - loss: 0.5681 - accuracy: 0.7142\n",
      "Epoch 47/100\n",
      "25724/25724 [==============================] - 10s 381us/sample - loss: 0.5679 - accuracy: 0.7141\n",
      "Epoch 48/100\n",
      "25724/25724 [==============================] - 14s 534us/sample - loss: 0.5682 - accuracy: 0.7140\n",
      "Epoch 49/100\n",
      "25724/25724 [==============================] - 15s 582us/sample - loss: 0.5679 - accuracy: 0.7140\n",
      "Epoch 50/100\n",
      "25504/25724 [============================>.] - ETA: 0s - loss: 0.5680 - accuracy: 0.7147\n",
      "Epoch 00050: saving model to checkpoints2/weights.50hdf5\n",
      "25724/25724 [==============================] - 10s 399us/sample - loss: 0.5677 - accuracy: 0.7146\n",
      "Epoch 51/100\n",
      "25724/25724 [==============================] - 10s 400us/sample - loss: 0.5676 - accuracy: 0.7146\n",
      "Epoch 52/100\n",
      "25724/25724 [==============================] - 9s 356us/sample - loss: 0.5681 - accuracy: 0.7150\n",
      "Epoch 53/100\n",
      "25724/25724 [==============================] - 4s 141us/sample - loss: 0.5677 - accuracy: 0.7141\n",
      "Epoch 54/100\n",
      "25724/25724 [==============================] - 3s 129us/sample - loss: 0.5674 - accuracy: 0.7148\n",
      "Epoch 55/100\n",
      "25600/25724 [============================>.] - ETA: 0s - loss: 0.5673 - accuracy: 0.7146\n",
      "Epoch 00055: saving model to checkpoints2/weights.55hdf5\n",
      "25724/25724 [==============================] - 3s 134us/sample - loss: 0.5675 - accuracy: 0.7144\n",
      "Epoch 56/100\n",
      "25724/25724 [==============================] - 4s 137us/sample - loss: 0.5672 - accuracy: 0.7152\n",
      "Epoch 57/100\n",
      "25724/25724 [==============================] - 4s 140us/sample - loss: 0.5679 - accuracy: 0.7146\n",
      "Epoch 58/100\n",
      "25724/25724 [==============================] - 4s 143us/sample - loss: 0.5676 - accuracy: 0.7151\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25724/25724 [==============================] - 4s 144us/sample - loss: 0.5675 - accuracy: 0.7152\n",
      "Epoch 60/100\n",
      "25664/25724 [============================>.] - ETA: 0s - loss: 0.5674 - accuracy: 0.7144\n",
      "Epoch 00060: saving model to checkpoints2/weights.60hdf5\n",
      "25724/25724 [==============================] - 4s 146us/sample - loss: 0.5674 - accuracy: 0.7145\n",
      "Epoch 61/100\n",
      "25724/25724 [==============================] - 8s 299us/sample - loss: 0.5671 - accuracy: 0.7140\n",
      "Epoch 62/100\n",
      "25724/25724 [==============================] - 11s 422us/sample - loss: 0.5670 - accuracy: 0.7149\n",
      "Epoch 63/100\n",
      "25724/25724 [==============================] - 10s 389us/sample - loss: 0.5674 - accuracy: 0.7154\n",
      "Epoch 64/100\n",
      "25724/25724 [==============================] - 6s 221us/sample - loss: 0.5673 - accuracy: 0.7140\n",
      "Epoch 65/100\n",
      "25696/25724 [============================>.] - ETA: 0s - loss: 0.5671 - accuracy: 0.7140\n",
      "Epoch 00065: saving model to checkpoints2/weights.65hdf5\n",
      "25724/25724 [==============================] - 6s 220us/sample - loss: 0.5670 - accuracy: 0.7141\n",
      "Epoch 66/100\n",
      "25724/25724 [==============================] - 5s 196us/sample - loss: 0.5666 - accuracy: 0.7159\n",
      "Epoch 67/100\n",
      "25724/25724 [==============================] - 4s 158us/sample - loss: 0.5670 - accuracy: 0.7151\n",
      "Epoch 68/100\n",
      "25724/25724 [==============================] - 4s 150us/sample - loss: 0.5672 - accuracy: 0.7132\n",
      "Epoch 69/100\n",
      "25724/25724 [==============================] - 4s 143us/sample - loss: 0.5670 - accuracy: 0.7134\n",
      "Epoch 70/100\n",
      "25696/25724 [============================>.] - ETA: 0s - loss: 0.5667 - accuracy: 0.7143\n",
      "Epoch 00070: saving model to checkpoints2/weights.70hdf5\n",
      "25724/25724 [==============================] - 4s 151us/sample - loss: 0.5666 - accuracy: 0.7144\n",
      "Epoch 71/100\n",
      "25724/25724 [==============================] - 4s 149us/sample - loss: 0.5671 - accuracy: 0.7149\n",
      "Epoch 72/100\n",
      "25724/25724 [==============================] - 4s 139us/sample - loss: 0.5666 - accuracy: 0.7154\n",
      "Epoch 73/100\n",
      "25724/25724 [==============================] - 4s 144us/sample - loss: 0.5667 - accuracy: 0.7156\n",
      "Epoch 74/100\n",
      "25724/25724 [==============================] - 4s 137us/sample - loss: 0.5666 - accuracy: 0.7155\n",
      "Epoch 75/100\n",
      "25696/25724 [============================>.] - ETA: 0s - loss: 0.5668 - accuracy: 0.7152\n",
      "Epoch 00075: saving model to checkpoints2/weights.75hdf5\n",
      "25724/25724 [==============================] - 4s 153us/sample - loss: 0.5667 - accuracy: 0.7153\n",
      "Epoch 76/100\n",
      "25724/25724 [==============================] - 5s 180us/sample - loss: 0.5663 - accuracy: 0.7158\n",
      "Epoch 77/100\n",
      "25724/25724 [==============================] - 4s 144us/sample - loss: 0.5674 - accuracy: 0.7149\n",
      "Epoch 78/100\n",
      "25724/25724 [==============================] - 3s 135us/sample - loss: 0.5668 - accuracy: 0.7152\n",
      "Epoch 79/100\n",
      "25724/25724 [==============================] - 4s 140us/sample - loss: 0.5665 - accuracy: 0.7168\n",
      "Epoch 80/100\n",
      "25536/25724 [============================>.] - ETA: 0s - loss: 0.5663 - accuracy: 0.7162\n",
      "Epoch 00080: saving model to checkpoints2/weights.80hdf5\n",
      "25724/25724 [==============================] - 4s 157us/sample - loss: 0.5663 - accuracy: 0.7162\n",
      "Epoch 81/100\n",
      "25724/25724 [==============================] - 4s 152us/sample - loss: 0.5660 - accuracy: 0.7165\n",
      "Epoch 82/100\n",
      "25724/25724 [==============================] - 4s 151us/sample - loss: 0.5664 - accuracy: 0.7143\n",
      "Epoch 83/100\n",
      "25724/25724 [==============================] - 5s 184us/sample - loss: 0.5669 - accuracy: 0.7141\n",
      "Epoch 84/100\n",
      "25724/25724 [==============================] - 4s 169us/sample - loss: 0.5671 - accuracy: 0.7140\n",
      "Epoch 85/100\n",
      "25408/25724 [============================>.] - ETA: 0s - loss: 0.5666 - accuracy: 0.7151\n",
      "Epoch 00085: saving model to checkpoints2/weights.85hdf5\n",
      "25724/25724 [==============================] - 4s 148us/sample - loss: 0.5664 - accuracy: 0.7151\n",
      "Epoch 86/100\n",
      "25724/25724 [==============================] - 4s 143us/sample - loss: 0.5663 - accuracy: 0.7145\n",
      "Epoch 87/100\n",
      "25724/25724 [==============================] - 3s 136us/sample - loss: 0.5663 - accuracy: 0.7146\n",
      "Epoch 88/100\n",
      "25724/25724 [==============================] - 4s 155us/sample - loss: 0.5665 - accuracy: 0.7147\n",
      "Epoch 89/100\n",
      "25724/25724 [==============================] - 4s 145us/sample - loss: 0.5664 - accuracy: 0.7162\n",
      "Epoch 90/100\n",
      "25376/25724 [============================>.] - ETA: 0s - loss: 0.5663 - accuracy: 0.7158\n",
      "Epoch 00090: saving model to checkpoints2/weights.90hdf5\n",
      "25724/25724 [==============================] - 4s 139us/sample - loss: 0.5663 - accuracy: 0.7159\n",
      "Epoch 91/100\n",
      "25724/25724 [==============================] - 4s 137us/sample - loss: 0.5661 - accuracy: 0.7152\n",
      "Epoch 92/100\n",
      "25724/25724 [==============================] - 5s 195us/sample - loss: 0.5665 - accuracy: 0.7147\n",
      "Epoch 93/100\n",
      "25724/25724 [==============================] - 5s 178us/sample - loss: 0.5666 - accuracy: 0.7138\n",
      "Epoch 94/100\n",
      "25724/25724 [==============================] - 4s 153us/sample - loss: 0.5664 - accuracy: 0.7142\n",
      "Epoch 95/100\n",
      "25440/25724 [============================>.] - ETA: 0s - loss: 0.5662 - accuracy: 0.7148\n",
      "Epoch 00095: saving model to checkpoints2/weights.95hdf5\n",
      "25724/25724 [==============================] - 5s 176us/sample - loss: 0.5663 - accuracy: 0.7149\n",
      "Epoch 96/100\n",
      "25724/25724 [==============================] - 4s 154us/sample - loss: 0.5666 - accuracy: 0.7148\n",
      "Epoch 97/100\n",
      "25724/25724 [==============================] - 4s 147us/sample - loss: 0.5661 - accuracy: 0.7145\n",
      "Epoch 98/100\n",
      "25724/25724 [==============================] - 4s 142us/sample - loss: 0.5658 - accuracy: 0.7152\n",
      "Epoch 99/100\n",
      "25724/25724 [==============================] - 4s 144us/sample - loss: 0.5659 - accuracy: 0.7154\n",
      "Epoch 100/100\n",
      "25632/25724 [============================>.] - ETA: 0s - loss: 0.5660 - accuracy: 0.7148\n",
      "Epoch 00100: saving model to checkpoints2/weights.100hdf5\n",
      "25724/25724 [==============================] - 4s 162us/sample - loss: 0.5660 - accuracy: 0.7149\n"
     ]
    }
   ],
   "source": [
    "# Import checkpoint dependencies\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the checkpoint path and filenames\n",
    "os.makedirs(\"checkpoints2/\", exist_ok=True)\n",
    "checkpoint_path = \"checkpoints2/weights.{epoch:02d}hdf5\"\n",
    "\n",
    "# Create a callback that saves the model's weights every epoch\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch',\n",
    "    period=5)\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(np.asarray(X_train_scaled),np.asarray(y_train),epochs=100,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "caa9888e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/1 - 1s - loss: 0.5425 - accuracy: 0.7092\n",
      "Loss: 0.5793476585744074, Accuracy: 0.7091545462608337\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(np.asarray(X_test_scaled),np.asarray(y_test),verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "657b7bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save(\"AlphabetSoupCharity.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14262587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
